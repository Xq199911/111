# Açº§è®ºæ–‡å®Œæ•´å®éªŒæŒ‡å—ï¼ˆé€šç”¨ç‰ˆï¼‰

> **æ³¨æ„**: æœ¬æŒ‡å—ä¸ºé€šç”¨ç‰ˆæœ¬ã€‚è¯·æ ¹æ®æ‚¨çš„æ“ä½œç³»ç»ŸæŸ¥çœ‹å¯¹åº”çš„è¯¦ç»†æŒ‡å—ï¼š
> - **Ubuntuç³»ç»Ÿ**: æŸ¥çœ‹ `scripts/ubuntu/README.md`
> - **Windowsç³»ç»Ÿ**: æŸ¥çœ‹ `scripts/windows/README.md`

## ğŸ¯ é¡¹ç›®ç›®æ ‡

**ç ”ç©¶é—®é¢˜**: Head-Aware Dynamic KV Budgeting for Efficient Long-Sequence Inference

**ç›®æ ‡**: å‘è¡¨Açº§ä¼šè®®/æœŸåˆŠè®ºæ–‡ï¼ˆACL, EMNLP, NeurIPS, ICMLç­‰ï¼‰

**æ ¸å¿ƒæ–¹æ³•**: 
- Head-Aware Cache: æ ¹æ®attention headçš„åŠŸèƒ½ç‰¹æ€§åŠ¨æ€åˆ†é…KV cacheé¢„ç®—
- Group-Aware Eviction: åŸºäºhead groupçš„ååŒevictionç­–ç•¥

**Baselineå¯¹æ¯”**:
- H2O (Heavy-Hitter Oracle)
- StreamingLLM (Fixed Window + Attention Sinks)

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
StreamingLLM/
â”œâ”€â”€ StreamingLLM_GPE/              # æ ¸å¿ƒä»£ç 
â”‚   â”œâ”€â”€ baselines/                 # Baselineå®ç°
â”‚   â”‚   â”œâ”€â”€ h2o_cache.py          # H2O baseline
â”‚   â”‚   â””â”€â”€ streamingllm_cache.py # StreamingLLM baseline
â”‚   â”œâ”€â”€ models/                    # æ¨¡å‹å®ç°
â”‚   â”‚   â”œâ”€â”€ Qwen2_5/              # Qwenæ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ Llama3/               # Llamaæ¨¡å‹
â”‚   â”‚   â””â”€â”€ Gemma2/               # Gemmaæ¨¡å‹
â”‚   â”œâ”€â”€ evaluate/                 # è¯„ä¼°è„šæœ¬
â”‚   â”‚   â””â”€â”€ multi_model_eval.py   # ä¸»è¯„ä¼°è„šæœ¬
â”‚   â”œâ”€â”€ utils/                     # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ configs/                   # é…ç½®æ–‡ä»¶
â”œâ”€â”€ models/                        # æ¨¡å‹æ–‡ä»¶ï¼ˆéœ€ä¸‹è½½ï¼‰
â”‚   â””â”€â”€ Qwen2.5-3B-Instruct/      # Qwenæ¨¡å‹
â”œâ”€â”€ data_raw/                      # åŸå§‹æ•°æ®
â”œâ”€â”€ output_logs/                   # å®éªŒç»“æœè¾“å‡º
â”œâ”€â”€ run_a_level_experiments.sh     # Açº§è®ºæ–‡å®éªŒè„šæœ¬ â­
â”œâ”€â”€ run_multi_model_experiments.sh # å¤šæ¨¡å‹å®éªŒè„šæœ¬
â”œâ”€â”€ download_models_china.py       # æ¨¡å‹ä¸‹è½½è„šæœ¬
â”œâ”€â”€ download_models_python38.py    # Python 3.8ä¸‹è½½è„šæœ¬
â”œâ”€â”€ check_environment.py           # ç¯å¢ƒæ£€æŸ¥
â”œâ”€â”€ check_model_integrity.py       # æ¨¡å‹æ£€æŸ¥
â”œâ”€â”€ analyze_experiment_results.py  # ç»“æœåˆ†æ
â”œâ”€â”€ visualize_results.py          # å¯è§†åŒ–
â”œâ”€â”€ test_baselines.py              # Baselineæµ‹è¯•
â””â”€â”€ EXPERIMENT_GUIDE.md            # æœ¬æ–‡ä»¶ â­
```

---

## ğŸ“‹ å®Œæ•´å®éªŒæµç¨‹ï¼ˆæŒ‰é¡ºåºæ‰§è¡Œï¼‰

### Step 0: ç¯å¢ƒå‡†å¤‡

**ç›®æ ‡**: ç¡®ä¿ç¯å¢ƒé…ç½®æ­£ç¡®

**æ‰§è¡Œå‘½ä»¤**:
```bash
# 1. æ£€æŸ¥Pythonç‰ˆæœ¬ï¼ˆéœ€è¦3.8+ï¼‰
python --version

# 2. æ£€æŸ¥GPUï¼ˆå¦‚æœä½¿ç”¨ï¼‰
nvidia-smi

# 3. æ£€æŸ¥ç¯å¢ƒä¾èµ–
python check_environment.py

# 4. å®‰è£…Pythonä¾èµ–
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
```

**éªŒè¯**: æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼Œæ— é”™è¯¯ä¿¡æ¯

**é¢„æœŸæ—¶é—´**: 5-10åˆ†é’Ÿ

---

### Step 1: ä¸‹è½½æ¨¡å‹

**ç›®æ ‡**: ä¸‹è½½å®éªŒæ‰€éœ€çš„å¤§è¯­è¨€æ¨¡å‹

**æ‰§è¡Œå‘½ä»¤**:
```bash
# æ–¹æ³•1: ç›´æ¥ä½¿ç”¨Pythonè„šæœ¬ï¼ˆæ¨èï¼Œé¿å…pipå‘½ä»¤é—®é¢˜ï¼‰
# Python 3.8
python3 download_models_python38.py --model Qwen2.5-3B-Instruct

# Python 3.9+
python3 download_models_china.py --model Qwen2.5-3B-Instruct --use-modelscope

# æ–¹æ³•2: ä½¿ç”¨bashè„šæœ¬ï¼ˆå¦‚æœpipå‘½ä»¤å¯ç”¨ï¼‰
bash setup_models_china.sh
```

**å¦‚æœé‡åˆ°pipå‘½ä»¤æ‰¾ä¸åˆ°çš„é”™è¯¯**:
```bash
# ä½¿ç”¨python -m pipå®‰è£…ä¾èµ–
python3 -m pip install huggingface_hub -i https://pypi.tuna.tsinghua.edu.cn/simple

# ç„¶åç›´æ¥ä½¿ç”¨Pythonè„šæœ¬ä¸‹è½½
python3 download_models_python38.py --model Qwen2.5-3B-Instruct
```

**éªŒè¯æ¨¡å‹**:
```bash
# æ£€æŸ¥æ¨¡å‹å®Œæ•´æ€§
python check_model_integrity.py ./models/Qwen2.5-3B-Instruct
```

**é¢„æœŸè¾“å‡º**: `Model integrity check passed`

**é¢„æœŸæ—¶é—´**: 2-4å°æ—¶ï¼ˆå–å†³äºç½‘ç»œï¼‰

**æ³¨æ„äº‹é¡¹**:
- è‡³å°‘éœ€è¦50GBç£ç›˜ç©ºé—´
- Qwen2.5-3B-Instructçº¦6GBï¼ˆå¿…é¡»ï¼‰
- Llama3-8B-Instructçº¦16GBï¼ˆå¯é€‰ï¼Œç”¨äºå¤šæ¨¡å‹éªŒè¯ï¼‰
- Gemma2-9B-Instructçº¦18GBï¼ˆå¯é€‰ï¼Œç”¨äºå¤šæ¨¡å‹éªŒè¯ï¼‰

---

### Step 2: æµ‹è¯•Baselineå®ç°

**ç›®æ ‡**: éªŒè¯H2Oå’ŒStreamingLLM baselineæ˜¯å¦æ­£ç¡®å®ç°

**æ‰§è¡Œå‘½ä»¤**:
```bash
# 1. åŸºç¡€åŠŸèƒ½æµ‹è¯•
python test_baselines.py

# 2. å°æ ·æœ¬çœŸå®æ¨¡å‹æµ‹è¯•ï¼ˆH2Oï¼‰
python StreamingLLM_GPE/evaluate/multi_model_eval.py \
    --LLM_backbone Qwen \
    --LLM_path ./models/Qwen2.5-3B-Instruct \
    --use_h2o \
    --h2o_budget 2048 \
    --output_dir ./output_logs/test_h2o \
    --max_samples 2 \
    --quantization 4bit

# 3. å°æ ·æœ¬çœŸå®æ¨¡å‹æµ‹è¯•ï¼ˆStreamingLLMï¼‰
python StreamingLLM_GPE/evaluate/multi_model_eval.py \
    --LLM_backbone Qwen \
    --LLM_path ./models/Qwen2.5-3B-Instruct \
    --use_streamingllm \
    --streamingllm_window 512 \
    --output_dir ./output_logs/test_streamingllm \
    --max_samples 2 \
    --quantization 4bit
```

**éªŒè¯è¾“å‡º**:
```bash
# æ£€æŸ¥ç»“æœæ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls -la ./output_logs/test_h2o/results.json
ls -la ./output_logs/test_streamingllm/results.json

# æŸ¥çœ‹ç»“æœ
cat ./output_logs/test_h2o/results.json | grep bleu
cat ./output_logs/test_streamingllm/results.json | grep bleu
```

**é¢„æœŸè¾“å‡º**: 
- `test_baselines.py` æ‰€æœ‰æµ‹è¯•é€šè¿‡
- ç”Ÿæˆresults.jsonæ–‡ä»¶
- BLEUåˆ†æ•°æ­£å¸¸ï¼ˆä¸ä¼šä¸º0æˆ–å¼‚å¸¸ä½ï¼‰

**é¢„æœŸæ—¶é—´**: 10-20åˆ†é’Ÿ

---

### Step 3: è¿è¡ŒAçº§è®ºæ–‡å®Œæ•´å®éªŒ â­â­â­â­â­

**ç›®æ ‡**: è¿è¡Œæ‰€æœ‰å¿…éœ€çš„å®éªŒï¼ˆé•¿åºåˆ—å¯¹æ¯”ã€æ¶ˆèå®éªŒã€é¢„ç®—åˆ†æï¼‰

**æ‰§è¡Œå‘½ä»¤**:
```bash
bash run_a_level_experiments.sh
```

**å®éªŒåŒ…å«çš„4ä¸ªé˜¶æ®µ**:

#### Phase 1: é•¿åºåˆ—å†…å­˜æ•ˆç‡å¯¹æ¯”

**æµ‹è¯•å†…å®¹**:
- åºåˆ—é•¿åº¦: 2000, 5000, 10000, 20000 tokens
- å¯¹æ¯”æ–¹æ³•: Baseline (GPE), H2O, StreamingLLM, Head-Aware, Full
- æ ·æœ¬æ•°: 100 samples/æ–¹æ³•

**è¾“å‡ºç›®å½•**: `./output_logs/a_level_paper/long_seq_{é•¿åº¦}/{æ–¹æ³•å}/`

**é¢„æœŸæ—¶é—´**: æ¯ä¸ªåºåˆ—é•¿åº¦çº¦2-4å°æ—¶

#### Phase 2: é¢„ç®—å½±å“åˆ†æ

**æµ‹è¯•å†…å®¹**:
- é¢„ç®—: 2048, 4096, 8192 tokens/layer
- æ–¹æ³•: Full (Head-Aware + Group-Aware)
- æ ·æœ¬æ•°: 100 samples

**è¾“å‡ºç›®å½•**: `./output_logs/a_level_paper/budget_{é¢„ç®—}/`

**é¢„æœŸæ—¶é—´**: çº¦1-2å°æ—¶

#### Phase 3: æ¶ˆèå®éªŒ

**æµ‹è¯•å†…å®¹**:
- åºåˆ—é•¿åº¦: 5000 tokens
- å¯¹æ¯”é…ç½®:
  1. Baseline (GPE only)
  2. Head-Aware only
  3. Group-Aware only
  4. Full (Head-Aware + Group-Aware)
- æ ·æœ¬æ•°: 100 samples/é…ç½®

**è¾“å‡ºç›®å½•**: `./output_logs/a_level_paper/ablation/{é…ç½®å}/`

**é¢„æœŸæ—¶é—´**: çº¦1-2å°æ—¶

#### Phase 4: ç»“æœåˆ†æå’Œå¯è§†åŒ–

**è‡ªåŠ¨æ‰§è¡Œ**:
- åˆ†æé•¿åºåˆ—å®éªŒç»“æœ
- åˆ†ææ¶ˆèå®éªŒç»“æœ
- ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨

**è¾“å‡ºæ–‡ä»¶**:
- `./output_logs/a_level_paper/long_seq_10000_summary.csv`
- `./output_logs/a_level_paper/ablation_summary.csv`
- `./output_logs/a_level_paper/figures/`

**é¢„æœŸæ—¶é—´**: 10-30åˆ†é’Ÿ

**æ€»é¢„æœŸæ—¶é—´**: 4-8å°æ—¶ï¼ˆå–å†³äºç¡¬ä»¶ï¼‰

**éªŒè¯å®éªŒè¿è¡Œ**:
```bash
# æ£€æŸ¥è¾“å‡ºç›®å½•
ls -la ./output_logs/a_level_paper/long_seq_10000/

# åº”è¯¥çœ‹åˆ°:
# baseline/
# h2o/
# streamingllm/
# head_aware/
# full/
```

---

### Step 4: å¤šæ¨¡å‹éªŒè¯ï¼ˆå¯é€‰ä½†æ¨èï¼‰

**ç›®æ ‡**: è¯æ˜æ–¹æ³•ä¸ä¾èµ–ç‰¹å®šæ¨¡å‹æ¶æ„

**æ‰§è¡Œå‘½ä»¤**:
```bash
bash run_multi_model_experiments.sh
```

**éªŒè¯çš„æ¨¡å‹**:
- Qwen2.5-3B-Instruct
- Llama3-8B-Instructï¼ˆå¦‚æœå·²ä¸‹è½½ï¼‰
- Gemma2-9B-Instructï¼ˆå¦‚æœå·²ä¸‹è½½ï¼‰

**è¾“å‡ºç›®å½•**: `./output_logs/multi_model/{æ¨¡å‹å}/`

**é¢„æœŸæ—¶é—´**: æ¯ä¸ªæ¨¡å‹çº¦1-2å¤©

**æ³¨æ„**: å¦‚æœåªæœ‰Qwenæ¨¡å‹ï¼Œå¯ä»¥è·³è¿‡æ­¤æ­¥éª¤ï¼Œå…ˆç”¨Qwenå®Œæˆæ‰€æœ‰å®éªŒ

---

### Step 5: ç»“æœåˆ†æå’Œè®ºæ–‡å‡†å¤‡

**ç›®æ ‡**: åˆ†æå®éªŒç»“æœï¼Œå‡†å¤‡è®ºæ–‡æ•°æ®

**æ‰§è¡Œå‘½ä»¤**:
```bash
# 1. åˆ†æé•¿åºåˆ—å®éªŒç»“æœ
python analyze_experiment_results.py \
    --output_dir ./output_logs/a_level_paper/long_seq_10000 \
    --detailed \
    --save_csv ./output_logs/long_seq_summary.csv \
    --save_json ./output_logs/long_seq_summary.json \
    --save_latex ./output_logs/long_seq_table.tex

# 2. åˆ†ææ¶ˆèå®éªŒç»“æœ
python analyze_experiment_results.py \
    --output_dir ./output_logs/a_level_paper/ablation \
    --detailed \
    --save_csv ./output_logs/ablation_summary.csv \
    --save_json ./output_logs/ablation_summary.json \
    --save_latex ./output_logs/ablation_table.tex

# 3. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
python visualize_results.py \
    --results_dir ./output_logs/a_level_paper \
    --output_dir ./output_logs/figures \
    --include_budget
```

**è¾“å‡ºæ–‡ä»¶**:
- CSVæ ¼å¼: ä¾¿äºExcelåˆ†æ
- JSONæ ¼å¼: ä¾¿äºç¨‹åºå¤„ç†
- LaTeXæ ¼å¼: ç›´æ¥ç”¨äºè®ºæ–‡è¡¨æ ¼
- å›¾è¡¨: PNG/PDFæ ¼å¼ï¼Œç”¨äºè®ºæ–‡æ’å›¾

**é¢„æœŸæ—¶é—´**: 1-2å°æ—¶

---

## ğŸ” éªŒè¯æ¸…å•

### ç¯å¢ƒå‡†å¤‡
- [ ] Python 3.8+ å·²å®‰è£…
- [ ] CUDAç¯å¢ƒé…ç½®æ­£ç¡®ï¼ˆå¦‚æœä½¿ç”¨GPUï¼‰
- [ ] ä¾èµ–åŒ…å·²å®‰è£…
- [ ] ç¯å¢ƒæ£€æŸ¥é€šè¿‡

### æ¨¡å‹ä¸‹è½½
- [ ] Qwen2.5-3B-Instruct å·²ä¸‹è½½å¹¶éªŒè¯
- [ ] æ¨¡å‹å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡

### Baselineæµ‹è¯•
- [ ] `test_baselines.py` æ‰€æœ‰æµ‹è¯•é€šè¿‡
- [ ] H2O baselineæµ‹è¯•æˆåŠŸ
- [ ] StreamingLLM baselineæµ‹è¯•æˆåŠŸ

### Açº§è®ºæ–‡å®éªŒ
- [ ] Phase 1: é•¿åºåˆ—å†…å­˜æ•ˆç‡å¯¹æ¯”å®Œæˆ
- [ ] Phase 2: é¢„ç®—å½±å“åˆ†æå®Œæˆ
- [ ] Phase 3: æ¶ˆèå®éªŒå®Œæˆ
- [ ] Phase 4: ç»“æœåˆ†æå’Œå¯è§†åŒ–å®Œæˆ

### ç»“æœéªŒè¯
- [ ] æ‰€æœ‰æ–¹æ³•çš„å®éªŒç»“æœæ–‡ä»¶å­˜åœ¨
- [ ] å†…å­˜ä½¿ç”¨æ•°æ®åˆç†
- [ ] BLEUåˆ†æ•°æ­£å¸¸
- [ ] å¯è§†åŒ–å›¾è¡¨ç”ŸæˆæˆåŠŸ

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆæœ€å°æµç¨‹ï¼‰

å¦‚æœæ—¶é—´æœ‰é™ï¼Œå¯ä»¥åªè¿è¡Œæ ¸å¿ƒå®éªŒï¼š

```bash
# 1. ç¯å¢ƒå‡†å¤‡
python check_environment.py
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple

# 2. ä¸‹è½½æ¨¡å‹ï¼ˆè‡³å°‘Qwenï¼‰
bash setup_models_china.sh
# æˆ–
python download_models_python38.py --model Qwen2.5-3B-Instruct

# 3. éªŒè¯æ¨¡å‹
python check_model_integrity.py ./models/Qwen2.5-3B-Instruct

# 4. æµ‹è¯•baseline
python test_baselines.py

# 5. è¿è¡Œå®Œæ•´å®éªŒ
bash run_a_level_experiments.sh

# 6. åˆ†æç»“æœ
python analyze_experiment_results.py \
    --output_dir ./output_logs/a_level_paper/long_seq_10000 \
    --detailed \
    --save_csv ./output_logs/summary.csv
```

---

## ğŸ“Š å®éªŒé…ç½®è¯´æ˜

### è¯„ä¼°è„šæœ¬å‚æ•°

**ä¸»è¦å‚æ•°**:
- `--LLM_backbone`: æ¨¡å‹æ¶æ„ (Qwen/Llama/Gemma)
- `--LLM_path`: æ¨¡å‹è·¯å¾„
- `--use_h2o`: ä½¿ç”¨H2O baseline
- `--use_streamingllm`: ä½¿ç”¨StreamingLLM baseline
- `--use_head_aware`: ä½¿ç”¨Head-Awareæ–¹æ³•
- `--use_group_aware`: ä½¿ç”¨Group-Awareæ–¹æ³•
- `--total_budget`: KV cacheé¢„ç®—ï¼ˆtokens/layerï¼‰
- `--max_samples`: æœ€å¤§æ ·æœ¬æ•°
- `--quantization`: é‡åŒ–ç­–ç•¥ (4bit/8bit/none)

**ç¤ºä¾‹å‘½ä»¤**:
```bash
# H2O baseline
python StreamingLLM_GPE/evaluate/multi_model_eval.py \
    --LLM_backbone Qwen \
    --LLM_path ./models/Qwen2.5-3B-Instruct \
    --use_h2o \
    --h2o_budget 2048 \
    --output_dir ./output_logs/h2o \
    --max_samples 100 \
    --quantization 4bit

# StreamingLLM baseline
python StreamingLLM_GPE/evaluate/multi_model_eval.py \
    --LLM_backbone Qwen \
    --LLM_path ./models/Qwen2.5-3B-Instruct \
    --use_streamingllm \
    --streamingllm_window 512 \
    --output_dir ./output_logs/streamingllm \
    --max_samples 100 \
    --quantization 4bit

# Head-Awareæ–¹æ³•
python StreamingLLM_GPE/evaluate/multi_model_eval.py \
    --LLM_backbone Qwen \
    --LLM_path ./models/Qwen2.5-3B-Instruct \
    --use_head_aware \
    --total_budget 2048 \
    --output_dir ./output_logs/head_aware \
    --max_samples 100 \
    --quantization 4bit

# Fullæ–¹æ³•ï¼ˆHead-Aware + Group-Awareï¼‰
python StreamingLLM_GPE/evaluate/multi_model_eval.py \
    --LLM_backbone Qwen \
    --LLM_path ./models/Qwen2.5-3B-Instruct \
    --use_head_aware \
    --use_group_aware \
    --total_budget 2048 \
    --output_dir ./output_logs/full \
    --max_samples 100 \
    --quantization 4bit
```

---

## âš ï¸ å¸¸è§é—®é¢˜

### é—®é¢˜1: æ¨¡å‹ä¸‹è½½å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥ç½‘ç»œè¿æ¥
- ä½¿ç”¨ModelScopeé•œåƒï¼ˆå¦‚æœPython 3.9+ï¼‰
- ä½¿ç”¨HuggingFace Tokenï¼ˆå¯¹äºLlama3ï¼‰
- å‚è€ƒ `download_models_python38.py` çš„è¯´æ˜

### é—®é¢˜2: æ˜¾å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**:
- ä½¿ç”¨4bité‡åŒ–: `--quantization 4bit`
- å‡å°‘æ ·æœ¬æ•°: `--max_samples 50`
- å‡å°‘é¢„ç®—: `--total_budget 1024`

### é—®é¢˜3: Baselineæµ‹è¯•å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥baselineæ–‡ä»¶æ˜¯å¦å­˜åœ¨: `ls -la StreamingLLM_GPE/baselines/`
- æ£€æŸ¥å¯¼å…¥: `python -c "from StreamingLLM_GPE.baselines import H2OCache, StreamingLLMCache"`
- æŸ¥çœ‹é”™è¯¯æ—¥å¿—

### é—®é¢˜4: å®éªŒç»“æœå¼‚å¸¸

**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ­£ç¡®åŠ è½½
- æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
- æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶: `./output_logs/{æ–¹æ³•å}/multi_model_eval.log`

---

## ğŸ“ æ€»ç»“

**æ ¸å¿ƒå®éªŒæµç¨‹**:
1. ç¯å¢ƒå‡†å¤‡ â†’ 2. ä¸‹è½½æ¨¡å‹ â†’ 3. æµ‹è¯•Baseline â†’ 4. è¿è¡Œå®Œæ•´å®éªŒ â†’ 5. åˆ†æç»“æœ

**å…³é”®æ–‡ä»¶**:
- `run_a_level_experiments.sh` - ä¸»å®éªŒè„šæœ¬
- `StreamingLLM_GPE/evaluate/multi_model_eval.py` - è¯„ä¼°è„šæœ¬
- `test_baselines.py` - Baselineæµ‹è¯•

**é¢„æœŸæ—¶é—´**:
- ç¯å¢ƒå‡†å¤‡: 10åˆ†é’Ÿ
- æ¨¡å‹ä¸‹è½½: 2-4å°æ—¶
- Baselineæµ‹è¯•: 20åˆ†é’Ÿ
- å®Œæ•´å®éªŒ: 4-8å°æ—¶
- ç»“æœåˆ†æ: 1-2å°æ—¶

**æ€»è®¡**: çº¦1-2å¤©ï¼ˆå–å†³äºç¡¬ä»¶å’Œç½‘ç»œï¼‰

