#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
é’ˆå¯¹Python 3.8çš„æ¨¡å‹ä¸‹è½½è„šæœ¬
æ”¯æŒHuggingFace Tokenè®¤è¯
"""
import os
import sys

# æ¨¡å‹é…ç½®
MODELS = {
    "Qwen2.5-3B-Instruct": {
        "huggingface": "Qwen/Qwen2.5-3B-Instruct",
        "modelscope": "qwen/Qwen2.5-3B-Instruct",
        "output_dir": "./models/Qwen2.5-3B-Instruct",
        "requires_auth": False
    },
    "Llama3-8B-Instruct": {
        "huggingface": "meta-llama/Meta-Llama-3-8B-Instruct",
        "modelscope": "LLM-Research/Meta-Llama-3-8B-Instruct",
        "output_dir": "./models/Llama3-8B-Instruct",
        "requires_auth": False  # ModelScopeä¸éœ€è¦è®¤è¯
    },
    "Gemma2-9B-Instruct": {
        "huggingface": "google/gemma-2-9b-it",
        "modelscope": "LLM-Research/gemma-2-9b-it",
        "output_dir": "./models/Gemma2-9B-Instruct",
        "requires_auth": False
    }
}

def download_with_modelscope(model_name, model_id, output_dir):
    """ä½¿ç”¨ModelScopeä¸‹è½½æ¨¡å‹ï¼ˆæ¨èæ–¹å¼ï¼‰"""
    try:
        import sys
        # æ£€æŸ¥Pythonç‰ˆæœ¬ï¼ˆModelScopeéœ€è¦Python 3.9+ï¼‰
        if sys.version_info < (3, 9):
            return False
        
        from modelscope import snapshot_download
        print(f"ğŸ“¥ Downloading {model_name} from ModelScope...")
        print(f"   Model ID: {model_id}")
        snapshot_download(
            model_id,
            cache_dir=None,
            local_dir=output_dir
        )
        print(f"âœ… {model_name} downloaded successfully from ModelScope")
        return True
    except ImportError:
        return False
    except Exception as e:
        print(f"âš ï¸  ModelScope download failed: {e}")
        return False

def download_with_git_clone(model_name, model_id, output_dir):
    """ä½¿ç”¨git cloneä»ModelScopeä¸‹è½½æ¨¡å‹ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰"""
    try:
        import subprocess
        import shutil
        
        # æ£€æŸ¥gitæ˜¯å¦å®‰è£…
        try:
            subprocess.run(["git", "--version"], capture_output=True, check=True)
        except (subprocess.CalledProcessError, FileNotFoundError):
            print("âš ï¸  git not found. Please install git first.")
            return False
        
        # æ£€æŸ¥git-lfsæ˜¯å¦å®‰è£…
        try:
            subprocess.run(["git", "lfs", "version"], capture_output=True, check=True)
        except (subprocess.CalledProcessError, FileNotFoundError):
            print("âš ï¸  git-lfs not found. Please install git-lfs first.")
            return False
        
        # æ„å»ºModelScope git URL
        git_url = f"https://www.modelscope.cn/{model_id}.git"
        
        print(f"ğŸ“¥ Downloading {model_name} from ModelScope using git clone...")
        print(f"   URL: {git_url}")
        
        # å¦‚æœè¾“å‡ºç›®å½•å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
        if os.path.exists(output_dir):
            shutil.rmtree(output_dir)
        
        # åˆå§‹åŒ–git-lfs
        subprocess.run(["git", "lfs", "install"], check=True)
        
        # å…‹éš†ä»“åº“
        subprocess.run(["git", "clone", git_url, output_dir], check=True)
        
        print(f"âœ… {model_name} downloaded successfully using git clone")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âš ï¸  git clone failed: {e}")
        return False
    except Exception as e:
        print(f"âš ï¸  git clone error: {e}")
        return False

def download_model(model_name, model_id, output_dir, requires_auth=False, modelscope_id=None):
    """ä¸‹è½½æ¨¡å‹"""
    print("=" * 70)
    print(f"Downloading Model: {model_name}")
    print("=" * 70)
    print(f"HuggingFace ID: {model_id}")
    if modelscope_id:
        print(f"ModelScope ID: {modelscope_id}")
    print(f"Output: {output_dir}")
    if requires_auth:
        print("âš ï¸  This model requires HuggingFace authentication (if using HuggingFace)")
    print()
    
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
    if os.path.exists(output_dir) and os.listdir(output_dir):
        print(f"âš ï¸  Model directory already exists: {output_dir}")
        response = input("Delete existing model and re-download? (y/n): ")
        if response.lower() == 'y':
            import shutil
            shutil.rmtree(output_dir)
            print(f"âœ… Deleted existing model directory")
        else:
            print("Skipping download")
            return True
    
    # è·å–token
    token = None
    if requires_auth:
        # ä»ç¯å¢ƒå˜é‡è·å–
        token = os.environ.get("HF_TOKEN") or os.environ.get("HUGGINGFACE_TOKEN")
        
        if not token:
            print("=" * 70)
            print("âš ï¸  HuggingFace Token Required!")
            print("=" * 70)
            print("This model requires HuggingFace authentication.")
            print()
            print("Steps to get token:")
            print("1. Visit: https://huggingface.co/settings/tokens")
            print("2. Create a new token with 'read' permission")
            print("3. Accept the model's license agreement:")
            print(f"   https://huggingface.co/{model_id}")
            print()
            print("Then set the token:")
            print("  export HF_TOKEN=your_token_here")
            print()
            response = input("Do you have a token? Enter it now (or press Enter to skip): ")
            if response.strip():
                token = response.strip()
            else:
                print("âŒ Token required. Skipping download.")
                return False
    
    # å°è¯•å¤šç§ä¸‹è½½æ–¹å¼
    success = False
    
    # ç­–ç•¥1: ä¼˜å…ˆä½¿ç”¨ModelScopeï¼ˆæ¨èï¼Œå›½å†…è®¿é—®å¿«ï¼Œæ— éœ€è®¤è¯ï¼‰
    if modelscope_id:
        import sys
        if sys.version_info >= (3, 9):
            print("ğŸ”„ Strategy 1: Trying ModelScope (recommended, no authentication needed)...")
            success = download_with_modelscope(model_name, modelscope_id, output_dir)
            print()
    
    # ç­–ç•¥2: å¦‚æœModelScopeå¤±è´¥ï¼Œå°è¯•git cloneï¼ˆå¯¹äºLlama3ç­‰æ¨¡å‹ï¼‰
    if not success and modelscope_id:
        print("ğŸ”„ Strategy 2: Trying ModelScope git clone...")
        success = download_with_git_clone(model_name, modelscope_id, output_dir)
        print()
    
    # ç­–ç•¥3: å¦‚æœéƒ½å¤±è´¥ï¼Œå°è¯•HuggingFaceé•œåƒ
    if not success:
        try:
            # è®¾ç½®HuggingFaceé•œåƒï¼ˆå¯é€‰ï¼‰
            use_mirror = os.environ.get("USE_HF_MIRROR", "true").lower() == "true"
            
            if use_mirror:
                os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
                print("ğŸ”„ Strategy 3: Trying HuggingFace mirror (hf-mirror.com)...")
            else:
                os.environ.pop("HF_ENDPOINT", None)
                print("ğŸ”„ Strategy 3: Trying HuggingFace directly...")
            
            # è®¾ç½®token
            if token:
                os.environ["HF_TOKEN"] = token
                print("ğŸ”‘ Using HuggingFace token for authentication")
            
            print(f"Downloading {model_name}...")
            print("This may take a while (several GB to download)...")
            print()
            
            from huggingface_hub import snapshot_download
            
            # æ–°ç‰ˆæœ¬huggingface_hubä¸å†æ”¯æŒlocal_dir_use_symlinkså‚æ•°
            download_kwargs = {
                "repo_id": model_id,
                "local_dir": output_dir,
            }
            
            if use_mirror:
                download_kwargs["endpoint"] = "https://hf-mirror.com"
            
            if token:
                download_kwargs["token"] = token
            
            snapshot_download(**download_kwargs)
            
            print()
            print("=" * 70)
            print(f"âœ… {model_name} downloaded successfully!")
            print(f"   Saved to: {output_dir}")
            print("=" * 70)
            return True
        except ImportError:
            print("âŒ huggingface_hub not installed")
            print("Installing...")
            os.system("pip install huggingface_hub -i https://pypi.tuna.tsinghua.edu.cn/simple")
            print("Please run the script again")
            return False
        except Exception as e:
            error_str = str(e)
            print()
            print("=" * 70)
            print(f"âŒ Error: {error_str}")
            print("=" * 70)
            
            if "403" in error_str or "gated" in error_str.lower() or "authentication" in error_str.lower():
                print()
                print("ğŸ’¡ This model requires HuggingFace authentication:")
                print("1. Get token from: https://huggingface.co/settings/tokens")
                print(f"2. Accept license: https://huggingface.co/{model_id}")
                print("3. Set token: export HF_TOKEN=your_token_here")
                print("4. Run this script again")
            elif "cannot find" in error_str.lower() or "connection" in error_str.lower():
                print()
                print("ğŸ’¡ Network or mirror issue. Try:")
                print("1. Use ModelScope instead (recommended)")
                print("2. Check internet connection")
                print("3. Try again later")
            
            return False
    
    if not success:
        print("=" * 70)
        print(f"âŒ {model_name} download failed with all methods!")
        print("=" * 70)
        print("\nğŸ’¡ Troubleshooting:")
        print("1. For Llama3/Gemma2: Use ModelScope (recommended)")
        print("2. Install ModelScope: pip install modelscope")
        print("3. Install git-lfs for git clone method")
        return False
    
    return True

def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Download models for Python 3.8",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Download Qwen (no auth needed)
  python download_models_python38.py --model Qwen2.5-3B-Instruct
  
  # Download Llama3 (requires token)
  export HF_TOKEN=your_token_here
  python download_models_python38.py --model Llama3-8B-Instruct
  
  # Download Gemma2 without mirror
  USE_HF_MIRROR=false python download_models_python38.py --model Gemma2-9B-Instruct
  
  # Download all (will prompt for token if needed)
  python download_models_python38.py --model all
        """
    )
    parser.add_argument(
        "--model",
        type=str,
        choices=list(MODELS.keys()) + ["all"],
        default="all",
        help="Model to download (default: all)"
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥ä¾èµ–
    try:
        import huggingface_hub
    except ImportError:
        print("Installing huggingface_hub...")
        os.system("pip install huggingface_hub -i https://pypi.tuna.tsinghua.edu.cn/simple")
        import huggingface_hub
    
    print()
    
    # ä¸‹è½½æ¨¡å‹
    if args.model == "all":
        print("Downloading all models...")
        print()
        success_count = 0
        for model_name, model_info in MODELS.items():
            if download_model(
                model_name,
                model_info["huggingface"],
                model_info["output_dir"],
                model_info["requires_auth"],
                model_info.get("modelscope")
            ):
                success_count += 1
            print()
        
        print("=" * 70)
        print(f"Download Summary: {success_count}/{len(MODELS)} models downloaded")
        print("=" * 70)
    else:
        model_info = MODELS[args.model]
        download_model(
            args.model,
            model_info["huggingface"],
            model_info["output_dir"],
            model_info["requires_auth"],
            model_info.get("modelscope")
        )

if __name__ == "__main__":
    main()

